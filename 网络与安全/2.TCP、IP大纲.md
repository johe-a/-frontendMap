# 前言
学习计算机网络时一般采用这种的方法，也就是中和OSI和TCP/IP的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。

![](https://tva1.sinaimg.cn/large/007S8ZIlgy1gfn9uktc5yj30hl09kabm.jpg)

# 五层网络协议体系结构
- 应用层
**应用层的任务是通过应用进程间的交互来完成特定网络应用**,是应用进程(主机中正在运行的程序)进行通信和交互的规则。不同的应用需要不同的应用层协议。例如域名解析系统DNS，HTTP协议，FTP协议，SMTP电子邮件协议等等。 应用层交互的数据单元称为报文。(个人理解，应用层通过不同协议来规定多种数据类型的报文，告诉对方数据类型是什么和如何解析等等)

- 传输层
**传输层的任务就是负责提供处于网络连接中的两台计算机之间通用的数据传输服务**。  
由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。复用就是指多个应用层进程可同时使用下面运输层的服务。分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。相关协议有TCP和UDP。(个人理解，传输层协议决定了数据的传输方式，是可靠还是不可靠，是一对一还是多对多等等)

- 网络层
进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。**网络层的任务就是选择合适的网间路由和交换结点**，确保数据及时传送。**该层规定了通过怎样的路径（所谓的传输路线）到达对方计算机，并把数据包传送给对方**，使用IP协议。（个人理解，网络层通过目标IP，不断的转发到交换结点，通过ARP找到MAC物理地址，最终构成一条传输路线到达对方计算机）

- 数据链路层
**两台主机之间的数据传输，总是在一段段的链路上传送的，这个时候就需要专门的链路层协议，来保证两个相邻节点之间传送数据时的可靠性。**总的来说，数据链路层将网络层交下来的IP数据报按照协议组装成帧，在两个相邻节点之间的链路上传送帧。每一帧包括数据和必要的控制信息，通过这些信息，接收端能够检测到所收到的帧有误差错(控制信息能够知道一个帧从哪个比特开始和结束)。（个人理解，数据链路层协议将IP数据报组装成帧，帧包含规定信息来确保传输正确）

- 物理层
在物理层上所传送的数据单位是比特。

# TCP/IP协议族的网络通信

TCP/IP协议族进行网络通信时，会通过分层顺序与对方进行通信，发送端从应用层往下走，接收端则往应用层往上走。

以HTTP为例，解释说明各层次在HTTP通信过程的作用：

1. 应用层根据HTTP协议封装报文，发起一个HTTP请求
2. 传输层(TCP协议)，把从应用层收到的HTTP报文进行分割，在各个报文上打上标记序号和端口号，转发给网络层
3. 网络层(IP协议)，通过ARP(address resolution protocol)一种转换IP地址为物理地址的协议(有可能不是本机解析的，可能是其他交换节点)，找到通信目的地的MAC地址(物理地址)，转发给链路层。
4. 链路层将IP数据报按照自己的协议组装成帧，在相邻节点之间传输。

![](https://tva1.sinaimg.cn/large/007S8ZIlgy1gfnaylpwo6j310z0u0nfm.jpg)

# 各层次对应的网络协议

![](https://tva1.sinaimg.cn/large/007S8ZIlgy1gfnbkw49sij30ic0su77b.jpg)


# 网络层
## ARP地址解析协议的工作原理
IP协议的作用是把各种数据包传送给对方。而要保证确实传送到对方那里，则需要满足各类条件。**其中两个重要的条件是IP地址和MAC地址(Media Access Control Address)**，**IP地址指明了节点被分配到的地址，MAC地址是指网卡所属的固定地址。IP地址可以和MAC地址进行配对。IP地址可变换，但MAC地址基本上不会更改。**而IP间的通信依赖MAC地址，这个时候ARP协议就起作用了，ARP(Address Resolution Protocol)用来解析IP地址得到MAC地址。

ARP协议完成了IP地址与MAC地址的映射。每台主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址的对应关系。当源主机将数据报发送到目的主机时，首先检查自己的ARP列表中是否存在IP对应的MAC地址，如果有，就直接将数据包发送到这个MAC地址，如果没有，就向本地网段发起一个ARP请求的广播包，查询此目的主机对应的MAC地址。在网络上，通信的双方在同一局域网 （LAN）内的情况是很少的，通常是经过多台计算机和网络设备中转才能连接到对方。而在进行中转时，会利用下一站中转设备的MAC地址来搜索下一个中转目标。

网络中所有的主机收到这个 ARP 请求后，会检查数据包中的目的 IP 是否和自己的 IP 地址一致。如果不相同就忽略此数据包；如果相同，该主机首先将发送端的 MAC 地址和 IP 地址添加到自己的 ARP 列表中，如果 ARP 表中已经存在该 IP 的信息，则将其覆盖，然后给源主机发送一个 ARP 响应数据包，告诉对方自己是它需要查找的 MAC 地址；源主机收到这个 ARP 响应数据包后，将得到的目的主机的 IP 地址和 MAC 地址添加到自己的 ARP 列表中，并利用此信息开始数据的传输。如果源主机一直没有收到 ARP 响应数据包，表示 ARP 查询失败。

简单来说，分为以下步骤
1. 查询自己的ARP，查看目标IP是否有对应的物理地址
   - 如果有，直接发送数据包，往数据链路层走
   - 如果没有，走向第二步
2. 广播一个ARP请求，该请求通过中转设备到达目的主机   
   - 如果找到目的主机，往第三步走
   - 如果没有响应，则查询失败
3. 目的主机通过ARP请求的IP地址与自己的IP核对，如果一致，则覆盖自己的ARP中源IP对应的物理地址，返回一个ARP响应请求。
4. 源主机收到ARP响应，更新自己的ARP，往数据链路层走


## IP地址分类的理解
IP 地址是指互联网协议地址，是 IP 协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。IP 地址编址方案将 IP 地址空间划分为 A、B、C、D、E 五类，其中 A、B、C 是基本类，D、E 类作为多播和保留使用，为特殊地址。

- A 类地址：以 0 开头，第一个字节范围：0~127
    - 8位第一位被占用，剩下7位，最大为2^7-1(八位2^7-1)
- B 类地址：以 10 开头，第一个字节范围：128~191
    - 占用两位，剩下6位，最小值为1000 0000等于128,范围为2^6-1=65,128+65 = 191
- C 类地址：以 110 开头，第一个字节范围：192~223
- D 类地址：以 1110 开头，第一个字节范围为 224~239
- E 类地址：以 1111 开头，保留地址

# 传输层
## TCP的主要特点
TCP全称为传输控制协议(Transmission Control Protocol)
1. TCP是面向连接的。(就像打电话一样，通话前需要先拨号建立连接，通话结束后要挂机释放连接)
2. 每一条TCP连接只能有两个端点，每一条TCP连接只能是点对点的(一对一)
3. TCP提供可靠交付的服务。通过TCP连接传送的数据，无差错、不丢失、不重复、并且按序到达。
4. TCP提供全双工通信。TCP允许通信双方的应用进程在任何时候都能发送数据。TCP连接的两端都设有发送缓存和接收缓存，用来临时存放双方通信的数据。
5. 面向字节流。TCP将大块数据分割成以报文段为单位的数据包进行管理，这样更容易传送大数据。


## UDP主要特点
UPD全称为用户数据报协议(User Data Protocol)
1. UDP是无连接的
2. UDP使用尽最大努力交付，即不保证可靠交付，因此主机不需要维持复杂的链接状态
3. UDP是面向报文的
4. UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低(对实时应用很有用，如直播、实时会议等)
5. UDP支持一对一、一对多、多对一和多对多的交互通信
6. UDP的首部开销小，只有8个字节，比TCP的20个字节的首部要短

## TCP和UDP的区别
- TCP提供面向连接的服务，在传送数据之前必须先建立连接，数据传送结束后要释放连接。TCP不提供广播或者多播服务。由于TCP要提供可靠的、面向连接的运输服务，这难以避免增加了许多开销。(TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞机制，在数据传完后，还会断开连接用来节约系统资源)。
- UDP在传送数据之前不需要先建立连接，远程主机在收到UDP报文后，不需要给出任何确认。虽然UDP不提供可靠交付，但在某些情况下UDP是一种最有效的工作方式，一般用于即时通信。

## TCP和UDP对应的应用层协议
TCP对应的应用层协议：
- FTP：定义了文件传输协议，使用21端口。下载文件，上传主页，都要用到FTP服务。
- Telnet：用于远程登录，用户可以以自己的身份远程连接到计算机上。
- SMTP：邮件传送协议，25号端口
- HTTP：超文本传输协议

UDP对应的应用层协议
- DNS：用于域名解析服务，将域名地址转换为IP地址。35号端口
- SNMP：简单网络管理协议，使用161号端口，用来管理网络设备。由于网络设备很多，无连接的服务就体现出其优势。
- TFTP：简单文件传输协议。

## TCP三次握手
TCP建立连接的过程叫做握手，握手需要在客户端和服务器之间交换三个TCP报文段。

![](https://tva1.sinaimg.cn/large/007S8ZIlgy1gfo9bv96y1j30i40bdabh.jpg)

1. 刚开始客户端处于Closed状态，服务端处于Listen状态
2. 第一次握手，客户端发送一个报文，报文首部中的同步位SYN=1，同时选择一个初始化序列号seq=x。TCP规定，SYN报文段不能懈怠数据，但要消耗掉一个序号。此时客户端进程进入SYN-SENT(同步已发送)状态。
3. 第二次握手，服务端收到连接请求报文后，如果同意建立链接，则向客户端发送确认报文，在确认报文段中把SYN和ACK都置为1，确认号是ack=x+1，同事也为自己选择一个初始化序列号seq=y。此时服务端进程进入SYN-RCVD(同步收到)状态。(处于半连接状态)
4. 第三次握手：TCP客户端收到服务端的确认报文后，还要向服务端给出确认。确认报文段的ACK置1，确认号ack=y_1,而自己的序列号seq=x+1。此时TCP连接已经建立,客户端处于ESTABLISHED(已经建立连接)状态，但是服务端还处于半连接状态，直到收到客户端的确认报文后，才会进入服务端的连接状态。

## TCP为什么要三次握手
我们要弄清楚三次握手的目的是什么，为什么不能用两次握手来达到相同的目的
- 第一次握手：客户端发送网络报，服务端收到了
此时服务端收到网络报，就可以得出结论：客户端的发送能力没问题，服务端的接收能力没问题。
- 第二次握手：服务端发包，客户端收到了
此时客户端收到确认报，就可以得到结论：客户端的接收能力没问题，服务端的发送能力也没问题。但这个结论是客户端得出的，服务端并不知道客户端的接收能力有没有问题。
- 第三次握手：客户端发包，服务端收到了
此时服务端就能得出结论：客户端的发送和接收能力是正常的，自己的发送和接收能力也是正常的，可以建立连接。

## 为什么不能两次握手
两种解释方式：
- 从上面三次握手的过程来解释，如果只有两次握手，服务端不知道客户端的接收能力有没有问题，就开启了TCP连接，如果客户端不处理这个连接或者没有接收到这个包，就会导致连接不成功，白白浪费服务端的资源。
- 从网络丢包的情况解释：客户端发起一个网络包，但由于延迟或者其他原因导致服务端暂时没有接收到。此时客户端就会再次发起一个网络包，与服务端进行连接。在一段延迟过后，之前延迟的包到达了服务端，服务端建立起了TCP连接，但此时客户端对于该包是出于丢弃状态，并不会建立连接，白白浪费服务端的资源。

也可以得出结论，从旁观者、客户端来看，两次握手就可以确认双方通信没问题，但从服务端来看，三次握手是确认双方通信没问题的最少握手次数，并且也确保服务器资源不会被浪费。(因为服务器在第三次握手才会建立连接)

## 什么是半连接队列
服务端第一次收到客户端的SYN之后，就会处于SYN_RCVD状态，此时双方还没有完全建立连接，服务器会把这种状态下的请求连接放在一个队列里。**我们把这种队列称之为半连接队列**

**全连接队列，指的是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能出现丢包现象。**

服务器发送完SYN-ACK包后，**如果未收到客户端确认包，服务器进行首次重传，等到一段时间仍未收到客户确认包，则进行第二次重传，如果重传次数超过系统规定的最大重传次数，系统将该连接从半连接队列中删除。**


## Server端为什么要回传SYN
**服务端回传SYN是为了告诉发送端，我收到的信息就是你所发的信号，这样客户端才能够确认服务端的接收和发送没有问题。**

## Client端为什么要回传ACK
SYN信号是为了证明发送方到接收方的通道没有问题(服务端回传是为了告诉客户端，我收到你的信号了，我的接收端没有问题)，ACK信号是为了证明，接收方到发送方的通道没有问题（客户端回传是为了告诉服务端，我收到你的信号了，客户端的接收端没有问题）

## 三次握手过程中可以携带数据吗
第三次握手的时候，可以携带数据，第一次和第二次握手不可以携带数据。

为什么这样呢?大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据。因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。

也就是说，第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。而对于第三次的话，此时客户端已经处于 ESTABLISHED 状态。对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也没啥毛病。

**简单理解，第一次握手是由客户端发起的，服务端在接收报文的时候如果有数据，需要消耗大量的资源去处理,而且第一次、第二次握手是为了确认通信是否有问题，此时客户端TCP为开启连接，服务端处于半连接状态，即使发送数据也没有意义**

## SYN攻击是什么
服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到SYN洪泛攻击。SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复确认包，并等待Client确认，由于源地址不存在，因此Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。

检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。在 Linux/Unix 上可以使用系统自带的 netstats 命令来检测 SYN 攻击。
```
netstat -n -p TCP | grep SYN_RECV
```
常见的防御SYN攻击的方法有如下几种：
- 缩短超时时间（SYN timeout)
- 增加最大半连接数
- 过滤网关防护
- SYN cookies技术

## TCP四次挥手过程
通信双方都可以释放连接，现在A和B都处于ESTABLISHED状态。
![](https://tva1.sinaimg.cn/large/007S8ZIlgy1gfosdqr37bj30ik0cvgno.jpg)

1. 第一次挥手：A的应用程序先向其TCP发出连接释放报文段，并停止发送数据，主动关闭TCP连接。A把连接释放报文段首部的终止控制位FIN置1，其序号seq = u 等于前面已经传送过的数据最后一个字节序号加1，这时候A进入FIN-WAIT-1（终止等待1）状态。等待B确认。

2. 第二次挥手：B收到连接释放报文段后立即发出确认，确认号是ack=u+1，而这个报文段自己的序号是v，等于B之前传送过的数据最后一个字节序号加1，然后B就进入CLOSE-WAIT(关闭等待)状态。TCP服务端进程这时应通知高层应用进程，因而A到B方向的连接就释放了，这时的TCP连接处于半关闭(half-close)状态，即A已经没有数据要发送了，但B若发送数据，A仍要接收。也就是说，B到A这个方向的连接并未关闭，这个状态可能会持续一段时间。A收到来自B的确认后，就进入FIN-WAIT-2(终止等待2)状态，等待B发出的连接释放报文段。

3. 第三次挥手：若B已经没有要向A发送的数据，其应用进程就通知TCP释放连接。这时B的连接释放报文必须使FIN=1，B还必须重复上次已经发送过的确认号ack=u+1，这时B就进入LAST-ACK(最后确认)状态，等待A的确认。

4. 第四次回收：A在收到B的连接释放报文后，必须对此发出确认。在确认报文段中把ACK置1，确认号ack=w+1，而自己的序号seq=u+1,然后进入TIME-WAIT(时间等待状态)，请注意，现在TCP连接还没有释放掉。必须经过时间等待计时器设置的时间2MSL(MSL:最长报文段寿命)后，A才能进入到CLOSED状态。B一收到A的确认就进入CLOSED状态，所以在释放连接时，B结束TCP的连接时间要早于A。

## 为什么需要四次挥手
- 第一次挥手，客户端发起一个FIN报文，服务端知道了客户端要关闭连接。
- 第二次挥手，第一次挥手后，服务端还不能立即关闭连接，还需要确认应用程序是否有数据要发送。此时服务端响应一个ACK报文，告诉客户端我收到了你的关闭请求，但是我还要确认有没有数据需要传输，请客户端先等等。客户端收到第二次挥手后，此时TCP处于半关闭状态，也就是客户端不再发送数据，但客户端仍需要接受服务端的数据。
- 第三次挥手，第二次和第三次挥手之间，应用程序持续发送消息，发送完之后，发起第三次挥手，服务端发送一个FIN报文，告诉客户端，服务端也可以关闭连接了，此时服务端处于最后确认状态
- 第四次挥手，客户端发起一个ACK报文，表示收到了服务端的关闭请求(这样服务端才能确认对方已经关闭连接，不浪费对方资源)，可以关闭TCP连接了。客户端此时需要等待2MSL(最大报文段寿命)，如果这段时间内服务端没有再次发送FIN报文，说明服务端已经接收到了第四次挥手，然后再关闭连接。

## 第四次挥手时TIME-WAIT状态必须等待2MSL的时间呢
假设发起断开的为A，A发送的最后一次ACK挥手报文可能会丢失，而B此时在等待A的响应之后才关闭，一旦B没有收到响应，就会重新发起FIN+ACK第三次挥手的报文，如果这个时候A没有等待，直接关闭了TCP连接，就会导致B收不到第四次挥手报文，而一直无法关闭TCP连接。

至于为什么是2MSL(最长报文段寿命)，我的理解是，第一个MSL是第四次挥手报文的超时时间，一旦超过这个时间，B就会发起FIN+ACK的第三次挥手报文，此时B的第三次挥手报文超时时间又是一个MSL，如果A在2MSL内都没有收到B重新发送的报文，说明B已经收到响应，A可以关闭TCP连接。

## 为什么第二次和第三次不能合并
当服务器执行第二次挥手之后，此时证明客户端不会再向服务端请求任何数据，但是服务端可能还正在给客户端发送数据(可能客户端上一次请求的资源还没有发送完毕)，所以第二次挥手是为了向客户端响应，表示我已经收到你的关闭请求，请你再等待一会，我要向应用程序确认是否还有数据发送。此时客户端处于TCP半关闭状态，也就是客户端不再发送数据，但是还需要接收服务端的数据。而第三次挥手，是在服务端确认没有数据要发送后，发起的关闭TCP请求的一次挥手报文，告诉客户端我已经没有数据要发送了，我们可以开始准备关闭TCP连接了。

## 为什么第三次和第四次不能合并
如果说TCP握手的第三次握手，是为了不让服务器浪费资源。那么TCP的第三次和第四次挥手，是为了不让服务器和客户端浪费资源，是一种确保双方资源不被浪费的手段。  
第三次和第四次挥手是如何确保双方资源不被浪费的？
- 客户端的时间等待机制
- 服务端的超时重试机制

## TCP协议是如何保证可靠传输的
1. 数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据；
2. 对失序数据包重排序：既然 TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TCP 报文段的到达也可能会失序。TCP 将对失序数据进行重新排序，然后才交给应用层；
3. 丢弃重复数据：对于重复数据，能够丢弃重复数据；
4. 应答机制：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒；
5. 超时重发：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段；
6. 流量控制(滑动窗口)：TCP 连接的每一方都有固定大小的缓冲空间。TCP 的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP 使用的流量控制协议是可变大小的滑动窗口协议。

## 停止等待协议
停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认

## 流量控制(滑动窗口)
TCP 利用滑动窗口实现流量控制的机制。滑动窗口（Sliding window）是一种流量控制技术。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。

TCP 中采用滑动窗口来进行传输控制，**滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。**当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

TCP利用滑动窗口实现流量控制，**流量控制是为了控制发送方速率，保证接收方来得及接收**。接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的速率。将窗口字段设置为0，则发送方不能发送数据。

**滑动窗口实现流量控制，是点对点的**

## TCP拥塞控制
**拥塞控制和流量控制不同，拥塞控制是一个全局性的过程，而流量控制（滑动窗口）指的是点对点通信量的控制。**  

**在某段时间内，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏，这种情况就叫做拥塞。**

拥塞控制就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或者链路不至于过载。拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机，所有的路由器。  
相反，流量控制是点对点通信量的控制。流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。

**为了进行拥塞控制，TCP发送方要维持一个拥塞窗口的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。**

拥塞控制采用了四种算法：慢开始、拥塞避免、快重传和快恢复。

- 慢开始
慢开始算法的思路是当主机开始发送数据时，如果立即把大量数据注入到网络，那么可能会引起网络阻塞。因为现在还不知道网络的拥塞情况。经验表明，较好的方法是先探测一下，**即由小到大逐渐增大发送窗口，也牛市由小到大逐渐增大拥塞窗口数值，cwnd(拥塞窗口)初始值为1，每经过一个传播轮次，cwnd加倍**

- 拥塞避免
拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢增大，即每经过一个往返时间 RTT 就把发送方的 cwnd 加 1。

- 快重传与快恢复


## TCP粘包
在Node中的net模块中，我们可以很方便的创建TCP的客户端和服务端，当客户端向服务端发起消息时，服务端接收的数据会出现两个数据包粘在一起的情况。

1. TCP是基于字节流的。虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块锦锦看成一连串无结构的字节流，没有边界;
2. 从TCP的帧结构首部没有表示数据长度的字段。

**这是TCP中常见的粘包问题，客户端在发送之前会将短时间有多个发送的数据块缓冲到一起(发送端缓冲区),形成一个大的数据块一并发送，同样接收端也有一个接收端缓冲区，收到的数据先存放在接收端缓冲区，然后程序从这里读取部分数据进行消费。这样做也是为了减少I/O消耗达到性能优化**

## TCP粘包是怎么产生的？
产生粘包的首要条件是客户端和服务端的连接是一个长连接的状态，一次连接发一次数据的情况下不存在粘包。
- 发送方产生的粘包
发送端存在一个发送端缓冲区，当发送的数据包过于小时，那么TCP协议默认采用Nagle算法，将这些较小的数据包进行合并发送，这个合并过程是在发送端缓冲区进行的，也就是说数据发送出来的时候就已经是粘包状态。

- 接收方产生的粘包
数据到接收端，从网络模型的下方传输至传输层，传输层的TCP协议处理是将其放置在接收端的缓冲区，然后由应用层来主动获取。这时会出现一个问题，就是应用层不能及时的将缓冲区的数据拿出来，而下一个数据又到来并有一部分放入缓冲区末尾，此时我们读取的数据就是一个粘包。即接收方缓冲区放数据的速度>应用层读取数据的速度。

## 怎么解决拆包和粘包
其实粘包是一种优化策略，这是为了减少I/O操作而进行的优化，而这种优化算法叫做Nagle算法。
1. 优化算法是由Nagle产生的，那么我们可以设置关闭Nagle优化算法，但是既然是优化算法，关闭显然是不推荐的。
2. 在TCP包头部添加包序号以及包长度。
```javascript
// transcoder.js

class Transcoder {
    constructor () {
        //消息头长度
        this.packageHeaderLen = 4;
        //消息头序号
        this.serialNumber = 0;
        //消息头序号占用的字节
        this.packageSerialNumberLen = 2; 
    }

    /**
     * 编码
     * @param { Object } data Buffer 对象数据
     * @param { Int } serialNumber 包序号，客户端编码时自动生成，服务端解码之后在编码时需要传入解码的包序列号
     */
    encode(data, serialNumber) {
        const body = Buffer.from(data);

        const header = Buffer.alloc(this.packageHeaderLen);
        //消息头写入序号、消息体的大小
        header.writeInt16BE(serialNumber || this.serialNumber);
        //从消息头序号之后写入消息体大小
        header.writeInt16BE(body.length, this.packageSerialNumberLen); 

        if (serialNumber === undefined) {
            this.serialNumber++;
        }

        return Buffer.concat([header, body]);
    }

    /**
     * 解码
     * @param { Object } buffer 
     */
    decode(buffer) {
        //获取消息头
        const header = buffer.slice(0, this.packageHeaderLen);
        //获取消息体
        const body = buffer.slice(this.packageHeaderLen); 

        return {
            serialNumber: header.readInt16BE(),
            bodyLength: header.readInt16BE(this.packageSerialNumberLen), // 因为编码阶段写入时跳过了前两位，解码同样也要跳过
            body: body.toString(),
        }
    }

    /**
     * 获取包长度两种情况：
     * 1. 如果当前 buffer 长度数据小于包头，肯定不是一个完整的数据包，因此直接返回 0 不做处理（可能数据还未接收完等等）
     * 2. 否则返回这个完整的数据包长度
     * @param {*} buffer 
     */
    getPackageLength(buffer) {
        if (buffer.length < this.packageHeaderLen) {
            return 0;
        }

        return this.packageHeaderLen + buffer.readInt16BE(this.packageSerialNumberLen);
    }
}

module.exports = Transcoder;


```

## 浏览器输入URL地址到显示主页的过程
![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbfry9pv9lj31cw0tiwr9.jpg)

上图过程中，与网络有关的过程(其实还少了缓存):
1. DNS解析：浏览器查询DNS（域名解析），获取域名对应的IP地址。
    - 浏览器DNS缓存:修改了本地host没生效的，就是因为浏览器还存在DNS缓存，可以手动清除
    - 系统DNS缓存(本地HOST文件/etc/hosts)
    - 路由器DNS缓存
    - 本地DNS服务器
    - 从上往下逐级查找
2. TCP连接:浏览器获得域名对应的IP地址以后，浏览器向服务器请求建立连接，进行三次握手
3. 发送HTTP请求:TCP连接建立起来以后，浏览器向服务器发送HTTP请求
4. 服务器处理请求并返回HTTP报文：服务器接收到这个请求，根据路径映射到特定的处理器处理，并将处理结果返回给浏览器。
5. 浏览器解析页面：浏览器解析并渲染视图，构建CSS树，DOM树，render树，然后布局，渲染。如果遇到对JS文件、CSS文件等资源的请求，重复以上步骤。
6. 连接结束。

## HTTP长连接和短连接
在HTTP1.0中默认使用短连接，客户端和服务端每进行一次HTTP操作，就会建立一次连接，任务结束就中断连接。当客户端访问web资源，例如js文件、图片、css文件等。每遇到一个资源，就会重新建立起一个HTTP会话。

而HTTP1.1开始，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议会在响应头加入这行代码:
```
Connection:keep-alive
```
在使用长连接的情况下，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。

Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件中设定这个时间。这个时间称为保活计时，如果给定的连在两小时内没有任何动作，服务器就向客户端发送一个探测报文，根据客户端主机响应，存在4个客户端状态：
- 客户端正常运行，此时客户端TCP响应正常，服务端将保活定时器复位。
- 客户端崩溃，服务端无法接收到探测的响应，服务端总共会发送10个这样的探测，每个间隔75秒，若服务器没有收到任何一个响应，它就认为客户端已经关闭并终止连接。
- 客户端崩溃并已经重新启动，服务器将收到一个对其保活探测的响应，这个响应是一个复位，使得服务器终止这个连接。
- 客户端正常响应，但服务器无法接收，与第二种情况类似。

## 长连接和短连接的优点和缺点
长连接的优缺点
- 优点：省去重复的TCP建立和关闭操作，减少资源浪费，节约时间
- 缺点：随着长连接变多，服务器需要保持过多长连接，这个时候如果服务端不才起一定的策略，例如保活计时，可能会导致服务器承受不住而崩溃。

短连接的优缺点
- 优点：对于服务器来说管理简单，存在的都是有用的链接。
- 缺点：对于频繁请求的客户端，需要花很多时间在建立连接上，浪费时间和带宽。


## HTTP1.0和1.1、2.0的变化
- HTTP1.1的主要变化
    1. 长连接，可以再一次TCP请求中不断发送请求。
    2. 支持只发送header不发送body,原因是先用header判断是否成功，再发数据，节省带宽。POST请求默认就是这样，这也是POST与GET请求的不同之处。
    3. host字段。
- HTTP2.0
    1. HTTP支持多路复用，同一个连接可以并发处理多个请求，方法是把HTTP数据包拆为多个帧，并发有序的发送，根据序号在另一端进行重组。而不需要一个个HTTP请求顺序到达。
    2. HTTP2.0支持服务端推送，服务端在HTTP请求到达后，除了返回数据之外，还推送了额外的内容给客户端。
    3. HTTP2.0压缩了请求头，同时基本单位是二进制帧流，这样的数据占用空间更少。
    4. HTTP2.0适用于HTTPS场景，因为其在HTTP和TCP中间加了一层SSL层。

## HTTPS的工作过程
1. 客户端发送自己支持的加密规则给服务器，告诉服务器要进行连接了
2. 服务器从中选出一套加密算法和hash算法以及自己的身份信息(地址等)以证书的形式发给浏览器，证书中包含服务器信息，加密公钥，证书的机构。
3. 客户端收到网站的证书之后要做下面的事情:
    1. 验证证书合法性
    2. 如果通过证书，浏览器会生成一串随机数，并用证书中的公钥进行加密
    3. 用约定好的hash算法计算握手消息，然后用生成的密钥进行加密，然后一起发送给服务器
4. 服务器接收到客户端传送来的信息，用私钥解析出密码，用密码解析握手消息，验证hash值是否和浏览器发来的一致。